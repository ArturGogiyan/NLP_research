{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ArturGogiyan/NLP_research/blob/master/XGBoost.ipynb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Configure environment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Following section required only if you're running this code in google collab, so if you need uncomment it and run"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# !git clone https://github.com/ArturGogiyan/NLP_research.git\n",
    "# %cd NLP_research\n",
    "# !pip install -r './requirements.txt'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset loading"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from common import utils\n",
    "\n",
    "!pip install 'dvc[s3]'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data=> (5000, 17)\n"
     ]
    }
   ],
   "source": [
    "df = utils.read_remote_dataset('s3bucket')\n",
    "\n",
    "print(\"Shape of data=>\", df.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Non-neural network processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Resources needed:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "from common import bagofwords"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## XGBoost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:58:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/basicec/PycharmProjects/NLP_research2/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.4597434542682396\n",
      "Recall = 0.37303161097325616\n",
      "Accuracy = 0.8412\n"
     ]
    }
   ],
   "source": [
    "def xgb_test(test_percentage):\n",
    "    texts_train, texts_test, y_train, y_test = utils.get_train_and_test(df, \"All\", test_percentage)\n",
    "    if len(texts_train) == 0:\n",
    "        print(\"Class entities amount is too small! Ignoring...\")\n",
    "        return [], [], []\n",
    "\n",
    "    bow = bagofwords.BagOfWords(texts_train)\n",
    "    X_train_bow = np.stack(list(map(bow.text_to_bow, texts_train)))\n",
    "    X_test_bow = np.stack(list(map(bow.text_to_bow, texts_test)))\n",
    "    D_train = xgb.DMatrix(X_train_bow, label=y_train)\n",
    "    D_test = xgb.DMatrix(X_test_bow, label=y_test)\n",
    "\n",
    "    param = {\n",
    "        'eta': 0.3,\n",
    "        'max_depth': 3,\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': len(list(df.columns.values))}\n",
    "\n",
    "    steps = 20\n",
    "\n",
    "    xgb_model = xgb.train(param, D_train, steps)\n",
    "\n",
    "    preds = xgb_model.predict(D_test)\n",
    "    best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "\n",
    "    print(\"Precision = {}\".format(precision_score(y_test, best_preds, average='macro')))\n",
    "    print(\"Recall = {}\".format(recall_score(y_test, best_preds, average='macro')))\n",
    "    print(\"Accuracy = {}\".format(accuracy_score(y_test, best_preds)))\n",
    "    return xgb_model, bow\n",
    "\n",
    "\n",
    "xgb_model, bow = xgb_test(50)\n",
    "xgb_model.save_model('./model/xgb.json')\n",
    "bow.save('./model/xgb_bow.json')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}